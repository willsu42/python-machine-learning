{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [ Workshop 1 ] - NCU AI Math Group\n",
    "# Intro to Reinforcement Learning - Cartpole\n",
    "2019/10/17\n",
    "\n",
    "**[ Reference ]**\n",
    "1. Richard Sutton and Andrew Barto , “Reinforcement Learning: An Introduction”, 2nd ed., MIT Press, 2018. http://www.andrew.cmu.edu/course/10-703/textbook/BartoSutton.pdf\n",
    "\n",
    "2. UC Berkeley - CS188 Spring 2014\n",
    "\"Lecture 10 Reinforcement Learning I\"\n",
    "https://youtu.be/IXuHxkpO5E8\n",
    "\n",
    "\n",
    "3. Denny Britz, \"Implementation of Reinforcement Learning Algorithms. Python, OpenAI Gym, Tensorflow. Exercises and Solutions to accompany Sutton's Book and David Silver's course.\"\n",
    "https://github.com/dennybritz/reinforcement-learning\n",
    "4. OpenAI - Gym \"A toolkit for developing and comparing reinforcement learning algorithms.\"\n",
    "https://github.com/openai/gym"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## < CONTENTS >\n",
    "#### 1. [Gym from OpenAI](#GymfromOpenAI)\n",
    "#### 2. [CartPole-v0](#CartPole-v0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------\n",
    "<a id='GymfromOpenAI'></a>\n",
    "## 1. Gym from OpenAI \n",
    "+ https://gym.openai.com/docs/\n",
    "+ **`Gym` is a toolkit for developing and comparing reinforcement learning algorithms.** It makes no assumptions about the structure of your agent, and is compatible with any numerical computation library, such as TensorFlow or Theano.\n",
    "\n",
    "+ The `gym` library is a collection of test problems — environments — that you can use to work out your reinforcement learning algorithms. These environments have a shared interface, allowing you to write general algorithms.\n",
    "\n",
    "+ **[ Installation ]**\n",
    "    + To get started, you’ll need to have Python 3.5+ installed. Simply install gym using pip:\n",
    "\n",
    "    + `pip install gym`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gym\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d2/88/a7186ffe1f33570ad3b8cd635996e5a3e3e155736e180ae6a2ad5e826a60/gym-0.15.3.tar.gz (1.6MB)\n",
      "\u001b[K    100% |████████████████████████████████| 1.6MB 607kB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy in /anaconda3/lib/python3.7/site-packages (from gym) (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.10.4 in /anaconda3/lib/python3.7/site-packages (from gym) (1.15.4)\n",
      "Requirement already satisfied: six in /anaconda3/lib/python3.7/site-packages (from gym) (1.12.0)\n",
      "Collecting pyglet<=1.3.2,>=1.2.0 (from gym)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1c/fc/dad5eaaab68f0c21e2f906a94ddb98175662cc5a654eee404d59554ce0fa/pyglet-1.3.2-py2.py3-none-any.whl (1.0MB)\n",
      "\u001b[K    100% |████████████████████████████████| 1.0MB 680kB/s ta 0:00:01\n",
      "\u001b[?25hCollecting cloudpickle~=1.2.0 (from gym)\n",
      "  Downloading https://files.pythonhosted.org/packages/c1/49/334e279caa3231255725c8e860fa93e72083567625573421db8875846c14/cloudpickle-1.2.2-py2.py3-none-any.whl\n",
      "Requirement already satisfied: future in /anaconda3/lib/python3.7/site-packages (from pyglet<=1.3.2,>=1.2.0->gym) (0.17.1)\n",
      "Building wheels for collected packages: gym\n",
      "  Running setup.py bdist_wheel for gym ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/willsu/Library/Caches/pip/wheels/8a/71/10/30f9b16332ecfd6318ac290445c696fe809bcbe40a05f9a799\n",
      "Successfully built gym\n",
      "\u001b[31mspyder 3.3.2 requires pyqt5<5.10; python_version >= \"3\", which is not installed.\u001b[0m\n",
      "Installing collected packages: pyglet, cloudpickle, gym\n",
      "  Found existing installation: cloudpickle 0.6.1\n",
      "    Uninstalling cloudpickle-0.6.1:\n",
      "      Successfully uninstalled cloudpickle-0.6.1\n",
      "Successfully installed cloudpickle-1.2.2 gym-0.15.3 pyglet-1.3.2\n"
     ]
    }
   ],
   "source": [
    " !pip install gym"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Available Environments from Gym\n",
    "> + `Classic control` (https://gym.openai.com/envs/#classic_control)\n",
    "+ `toy text` (https://gym.openai.com/envs/#toy_text)\n",
    "+ `Algorithmic` (https://gym.openai.com/envs/#algorithmic) \n",
    "+ `Atari` (https://gym.openai.com/envs/#atari) \n",
    "+ `2D and 3D robots` (https://gym.openai.com/envs/#mujoco)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------\n",
    "<a id='CartPole-v0'></a>\n",
    "## 2. CartPole-v0\n",
    "> + **cartpole.py** : https://github.com/openai/gym/blob/master/gym/envs/classic_control/cartpole.py#L75\n",
    "+ **CartPole-v0** (https://gym.openai.com/envs/CartPole-v0/#barto83)\n",
    "    + A pole is attached by an un-actuated joint to a cart, which moves along a frictionless track. The system is controlled by applying a force of +1 or -1 to the cart. \n",
    "    + The pendulum starts upright, and the goal is to prevent it from falling over. \n",
    "    + A reward of +1 is provided for every timestep that the pole remains upright. \n",
    "    + The episode ends when the pole is more than 15 degrees from vertical, or the cart moves more than 2.4 units from the center.\n",
    "    + CartPole-v0 defines \"solving\" as getting average reward of 195.0 over 100 consecutive trials.\n",
    "\n",
    "**This environment corresponds to the version of the cart-pole problem described by Barto, Sutton, and Anderson (1983):** \n",
    "+ AG Barto, RS Sutton and CW Anderson, \"**Neuronlike Adaptive Elements That Can Solve Difficult Learning Control Problem**\", IEEE Transactions on Systems, Man, and Cybernetics, 1983.\n",
    "+ http://www.derongliu.org/adp/adp-cdrom/Barto1983.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The environment’s `step` function returns exactly what we need. In fact, `step` returns four values. These are:\n",
    "\n",
    ">+ `observation` (**object**): an environment-specific object representing your observation of the environment. For example, pixel data from a camera, joint angles and joint velocities of a robot, or the board state in a board game.\n",
    "+ `reward` (**float**): amount of reward achieved by the previous action. The scale varies between environments, but the goal is always to increase your total reward.\n",
    "+ `done` (**boolean**): whether it’s time to reset the environment again. Most (but not all) tasks are divided up into well-defined episodes, and done being True indicates the episode has terminated. (For example, perhaps the pole tipped too far, or you lost your last life.)\n",
    "+ `info` (**dict**): diagnostic information useful for debugging. It can sometimes be useful for learning (for example, it might contain the raw probabilities behind the environment’s last state change). However, official evaluations of your agent are not allowed to use this for learning.\n",
    "\n",
    "This is just an implementation of the classic “agent-environment loop”. Each timestep, the agent chooses an action, and the environment returns an observation and a reward.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **[NOTE]**:\n",
    "+ **The general-purpose agents don't need to know the semantics of the observations: they can learn how to map observations to actions to maximize reward without any prior knowledge.**\n",
    "\n",
    "\n",
    "> + 4 numbers in `observation`:\n",
    "**[position of cart, velocity of cart, angle of pole, rotation rate of pole]**. \n",
    "+ Defined at https://github.com/openai/gym/blob/master/gym/envs/classic_control/cartpole.py#L75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.00974793  0.01805022 -0.01929365 -0.00355016]\n",
      "[-0.00938693 -0.1767898  -0.01936465  0.28298349]\n",
      "[-0.01292272  0.01860293 -0.01370498 -0.0157435 ]\n",
      "[-0.01255066  0.21391872 -0.01401985 -0.31271881]\n",
      "[-0.00827229  0.40923756 -0.02027423 -0.60978998]\n",
      "[-8.75389532e-05  6.04636962e-01 -3.24700305e-02 -9.08789067e-01]\n",
      "[ 0.0120052   0.40996921 -0.05064581 -0.62648586]\n",
      "[ 0.02020458  0.21558941 -0.06317553 -0.35017353]\n",
      "[ 0.02451637  0.02142016 -0.070179   -0.07806193]\n",
      "[ 0.02494478  0.21747433 -0.07174024 -0.39203498]\n",
      "[ 0.02929426  0.0234399  -0.07958094 -0.12280555]\n",
      "[ 0.02976306 -0.17045706 -0.08203705  0.1437473 ]\n",
      "[ 0.02635392  0.0257381  -0.0791621  -0.17364754]\n",
      "[ 0.02686868 -0.16816689 -0.08263505  0.09304971]\n",
      "[ 0.02350534  0.02803628 -0.08077406 -0.22451783]\n",
      "[ 0.02406607  0.22421419 -0.08526442 -0.54154703]\n",
      "[ 0.02855035  0.42042456 -0.09609536 -0.85983075]\n",
      "[ 0.03695884  0.61671476 -0.11329197 -1.18111622]\n",
      "[ 0.04929314  0.42323079 -0.1369143  -0.92598744]\n",
      "[ 0.05775776  0.23019688 -0.15543404 -0.6792734 ]\n",
      "[ 0.06236169  0.03753651 -0.16901951 -0.43928062]\n",
      "[ 0.06311242  0.23459687 -0.17780513 -0.78011452]\n",
      "[ 0.06780436  0.43165931 -0.19340742 -1.12304763]\n",
      "Episode 0 finished after 23 timesteps : Reward 1.0\n",
      "[-0.04156472 -0.03733495 -0.00900182  0.02429411]\n",
      "[-0.04231142  0.15791493 -0.00851594 -0.27121534]\n",
      "[-0.03915312  0.35315736 -0.01394024 -0.56657202]\n",
      "[-0.03208997  0.15823372 -0.02527168 -0.27831326]\n",
      "[-0.0289253  -0.03651877 -0.03083795  0.0062931 ]\n",
      "[-0.02965567 -0.2311852  -0.03071209  0.289089  ]\n",
      "[-0.03427938 -0.03563906 -0.02493031 -0.01311982]\n",
      "[-0.03499216 -0.23039477 -0.0251927   0.27159422]\n",
      "[-0.03960005 -0.42514835 -0.01976082  0.55622601]\n",
      "[-0.04810302 -0.22975462 -0.0086363   0.25738334]\n",
      "[-0.05269811 -0.03451044 -0.00348863 -0.03801105]\n",
      "[-0.05338832 -0.22958219 -0.00424885  0.25356914]\n",
      "[-0.05797996 -0.42464322  0.00082253  0.54490888]\n",
      "[-0.06647283 -0.61977672  0.01172071  0.83785086]\n",
      "[-0.07886836 -0.81505675  0.02847773  1.1341966 ]\n",
      "[-0.0951695  -1.01053956  0.05116166  1.43567325]\n",
      "[-0.11538029 -0.81608444  0.07987512  1.15940719]\n",
      "[-0.13170198 -0.62208888  0.10306327  0.89279995]\n",
      "[-0.14414376 -0.42850448  0.12091926  0.63421117]\n",
      "[-0.15271385 -0.23525824  0.13360349  0.38192208]\n",
      "[-0.15741901 -0.43199915  0.14124193  0.71356618]\n",
      "[-0.16605899 -0.23908578  0.15551325  0.4684649 ]\n",
      "[-0.17084071 -0.43602338  0.16488255  0.8058432 ]\n",
      "[-0.17956118 -0.63297513  0.18099942  1.14552025]\n",
      "[-0.19222068 -0.44061829  0.20390982  0.91462217]\n",
      "Episode 1 finished after 25 timesteps : Reward 1.0\n",
      "[ 0.03844474 -0.04378171 -0.04651241  0.02342516]\n",
      "[ 0.0375691  -0.23820683 -0.04604391  0.30107772]\n",
      "[ 0.03280497 -0.43264331 -0.04002235  0.57889121]\n",
      "[ 0.0241521  -0.23698399 -0.02844453  0.27387382]\n",
      "[ 0.01941242 -0.04146798 -0.02296705 -0.02764313]\n",
      "[ 0.01858306  0.15397568 -0.02351992 -0.32748302]\n",
      "[ 0.02166258  0.34942444 -0.03006958 -0.6274893 ]\n",
      "[ 0.02865107  0.5449529  -0.04261936 -0.92948852]\n",
      "[ 0.03955012  0.74062343 -0.06120913 -1.23525409]\n",
      "[ 0.05436259  0.54633925 -0.08591421 -0.96235782]\n",
      "[ 0.06528938  0.3524703  -0.10516137 -0.6978547 ]\n",
      "[ 0.07233878  0.15895156 -0.11911846 -0.44004069]\n",
      "[ 0.07551781 -0.03430092 -0.12791928 -0.18715417]\n",
      "[ 0.0748318  -0.22738271 -0.13166236  0.06259636]\n",
      "[ 0.07028414 -0.42039527 -0.13041043  0.31101242]\n",
      "[ 0.06187624 -0.61344148 -0.12419019  0.55989081]\n",
      "[ 0.04960741 -0.41681536 -0.11299237  0.23080503]\n",
      "[ 0.0412711  -0.22027538 -0.10837627 -0.0952741 ]\n",
      "[ 0.03686559 -0.02378046 -0.11028175 -0.42008752]\n",
      "[ 0.03638998 -0.21718114 -0.1186835  -0.16410598]\n",
      "[ 0.03204636 -0.02057783 -0.12196562 -0.4917475 ]\n",
      "[ 0.0316348   0.17603435 -0.13180057 -0.82024399]\n",
      "[ 0.03515549  0.37268991 -0.14820545 -1.15130619]\n",
      "[ 0.04260929  0.56940156 -0.17123157 -1.4865521 ]\n",
      "[ 0.05399732  0.37672957 -0.20096262 -1.25186709]\n",
      "Episode 2 finished after 25 timesteps : Reward 1.0\n",
      "[ 0.01072763 -0.00714611 -0.01614808  0.04997819]\n",
      "[ 0.0105847  -0.20203284 -0.01514852  0.33752283]\n",
      "[ 0.00654405 -0.00669863 -0.00839806  0.04010165]\n",
      "[ 0.00641007  0.18854273 -0.00759603 -0.25521907]\n",
      "[ 0.01018093  0.38377231 -0.01270041 -0.5502882 ]\n",
      "[ 0.01785637  0.57907033 -0.02370617 -0.84694542]\n",
      "[ 0.02943778  0.38427965 -0.04064508 -0.56181047]\n",
      "[ 0.03712337  0.57994772 -0.05188129 -0.86701653]\n",
      "[ 0.04872233  0.77573583 -0.06922162 -1.1755498 ]\n",
      "[ 0.06423705  0.97168551 -0.09273262 -1.48910532]\n",
      "[ 0.08367076  1.1678064  -0.12251472 -1.809247  ]\n",
      "[ 0.10702688  0.9742452  -0.15869966 -1.55701077]\n",
      "[ 0.12651179  1.17087202 -0.18983988 -1.89470676]\n",
      "Episode 3 finished after 13 timesteps : Reward 1.0\n",
      "[-0.04244853 -0.01532577  0.03086423  0.0467191 ]\n",
      "[-0.04275504  0.17934033  0.03179861 -0.23606833]\n",
      "[-0.03916824 -0.01622116  0.02707724  0.06647282]\n",
      "[-0.03949266  0.17850233  0.0284067  -0.2175456 ]\n",
      "[-0.03592261 -0.01701395  0.02405579  0.08396093]\n",
      "[-0.03626289 -0.21247232  0.025735    0.38413538]\n",
      "[-0.04051234 -0.40795001  0.03341771  0.68482008]\n",
      "[-0.04867134 -0.6035196   0.04711411  0.98783366]\n",
      "[-0.06074173 -0.79923964  0.06687079  1.29493437]\n",
      "[-0.07672652 -0.99514444  0.09276947  1.60778015]\n",
      "[-0.09662941 -1.19123247  0.12492508  1.92788255]\n",
      "[-0.12045406 -1.38745273  0.16348273  2.25655175]\n",
      "[-0.14820312 -1.58368882  0.20861376  2.5948312 ]\n",
      "Episode 4 finished after 13 timesteps : Reward 1.0\n",
      "[-0.04293467  0.00541891  0.03193517 -0.03809819]\n",
      "[-0.04282629  0.2000687   0.03117321 -0.32053666]\n",
      "[-0.03882491  0.00451699  0.02476248 -0.01818817]\n",
      "[-0.03873458  0.19927523  0.02439871 -0.30295654]\n",
      "[-0.03474907  0.0038142   0.01833958 -0.00267975]\n",
      "[-0.03467279  0.1986684   0.01828599 -0.28952036]\n",
      "[-0.03069942  0.39352489  0.01249558 -0.57638045]\n",
      "[-0.02282892  0.58846948  0.00096797 -0.8651009 ]\n",
      "[-0.01105953  0.39333436 -0.01633405 -0.57211379]\n",
      "[-0.00319284  0.5886815  -0.02777632 -0.8698974 ]\n",
      "[ 0.00858079  0.39394818 -0.04517427 -0.58607528]\n",
      "[ 0.01645975  0.1994871  -0.05689578 -0.30795796]\n",
      "[ 0.02044949  0.00522006 -0.06305494 -0.03374726]\n",
      "[ 0.02055389 -0.18894365 -0.06372988  0.23839364]\n",
      "[ 0.01677502 -0.3831     -0.05896201  0.51031304]\n",
      "[ 0.00911302 -0.57734392 -0.04875575  0.78384782]\n",
      "[-0.00243386 -0.38158709 -0.03307879  0.47623298]\n",
      "[-0.0100656  -0.57622673 -0.02355413  0.75830933]\n",
      "[-0.02159014 -0.38078825 -0.00838794  0.45830865]\n",
      "[-0.0292059  -0.57579062  0.00077823  0.7483359 ]\n",
      "[-0.04072171 -0.7709233   0.01574495  1.04126363]\n",
      "[-0.05614018 -0.576014    0.03657022  0.75356474]\n",
      "[-0.06766046 -0.77162056  0.05164151  1.05752766]\n",
      "[-0.08309287 -0.96738733  0.07279207  1.36596219]\n",
      "[-0.10244062 -1.16334131  0.10011131  1.68049675]\n",
      "[-0.12570744 -1.35947072  0.13372125  2.00260143]\n",
      "[-0.15289686 -1.16597377  0.17377327  1.75414413]\n",
      "[-0.17621633 -1.3625889   0.20885616  2.09545771]\n",
      "Episode 5 finished after 28 timesteps : Reward 1.0\n",
      "[-0.03702391  0.03909537 -0.00377062 -0.0323032 ]\n",
      "[-0.036242    0.23427119 -0.00441668 -0.32617341]\n",
      "[-0.03155658  0.42945575 -0.01094015 -0.62024589]\n",
      "[-0.02296746  0.62472877 -0.02334507 -0.91635423]\n",
      "[-0.01047289  0.82015849 -0.04167216 -1.21628176]\n",
      "[ 0.00593028  0.62559806 -0.06599779 -0.93694256]\n",
      "[ 0.01844224  0.43142518 -0.08473664 -0.6657066 ]\n",
      "[ 0.02707075  0.23757768 -0.09805077 -0.4008614 ]\n",
      "[ 0.0318223   0.04397334 -0.106068   -0.1406305 ]\n",
      "[ 0.03270177  0.2404419  -0.10888061 -0.46480269]\n",
      "[ 0.03751061  0.04701337 -0.11817667 -0.2083257 ]\n",
      "[ 0.03845087 -0.14623792 -0.12234318  0.04486629]\n",
      "[ 0.03552611 -0.33941247 -0.12144585  0.29658304]\n",
      "[ 0.02873786 -0.53261271 -0.11551419  0.54863149]\n",
      "[ 0.01808561 -0.3360737  -0.10454156  0.22190198]\n",
      "[ 0.01136414 -0.1396249  -0.10010352 -0.1018417 ]\n",
      "[ 0.00857164  0.05677857 -0.10214036 -0.42435338]\n",
      "[ 0.00970721  0.25318787 -0.11062742 -0.74740894]\n",
      "[ 0.01477097  0.05975191 -0.1255756  -0.49148687]\n",
      "[ 0.01596601 -0.1333958  -0.13540534 -0.24086892]\n",
      "[ 0.01329809  0.06337441 -0.14022272 -0.57301021]\n",
      "[ 0.01456558 -0.12953185 -0.15168292 -0.32758143]\n",
      "[ 0.01197494  0.06738744 -0.15823455 -0.66399286]\n",
      "[ 0.01332269  0.26431546 -0.17151441 -1.00202162]\n",
      "[ 0.018609    0.46126225 -0.19155484 -1.34328561]\n",
      "Episode 6 finished after 25 timesteps : Reward 1.0\n",
      "[ 0.00530386 -0.03272148 -0.04262725 -0.00768751]\n",
      "[ 0.00464943  0.16298506 -0.042781   -0.31350926]\n",
      "[ 0.00790913  0.35868952 -0.04905119 -0.61937112]\n",
      "[ 0.01508292  0.55446102 -0.06143861 -0.92709044]\n",
      "[ 0.02617214  0.36022006 -0.07998042 -0.65433033]\n",
      "[ 0.03337654  0.55635918 -0.09306702 -0.97108769]\n",
      "[ 0.04450372  0.75259865 -0.11248878 -1.29149523]\n",
      "[ 0.0595557   0.55907214 -0.13831868 -1.03604216]\n",
      "[ 0.07073714  0.75573463 -0.15903953 -1.36875462]\n",
      "[ 0.08585183  0.9524487  -0.18641462 -1.70666264]\n",
      "Episode 7 finished after 10 timesteps : Reward 1.0\n",
      "[ 0.04549645 -0.02470156  0.0189618   0.04561273]\n",
      "[ 0.04500242  0.17014343  0.01987406 -0.24102777]\n",
      "[ 0.04840529 -0.0252567   0.0150535   0.05785712]\n",
      "[ 0.04790015  0.16964621  0.01621064 -0.23003856]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.05129308  0.36453281  0.01160987 -0.51756433]\n",
      "[ 0.05858373  0.55948938  0.00125859 -0.80656625]\n",
      "[ 0.06977352  0.3643502  -0.01487274 -0.51348769]\n",
      "[ 0.07706052  0.55967843 -0.02514249 -0.81082006]\n",
      "[ 0.08825409  0.36490979 -0.04135889 -0.52615055]\n",
      "[ 0.09555229  0.56058857 -0.0518819  -0.83157376]\n",
      "[ 0.10676406  0.75637974 -0.06851338 -1.14011177]\n",
      "[ 0.12189166  0.95232718 -0.09131561 -1.45347054]\n",
      "[ 0.1409382   0.75843759 -0.12038503 -1.19065737]\n",
      "[ 0.15610695  0.95489598 -0.14419817 -1.51851992]\n",
      "[ 0.17520487  1.15143716 -0.17456857 -1.85251947]\n",
      "Episode 8 finished after 15 timesteps : Reward 1.0\n",
      "[ 0.0026991  -0.02615602  0.03792886  0.01853285]\n",
      "[ 0.00217598 -0.22180081  0.03829952  0.32293738]\n",
      "[-0.00226003 -0.02724457  0.04475827  0.04257434]\n",
      "[-0.00280492  0.16720794  0.04560976 -0.23565777]\n",
      "[ 0.00053924 -0.02853498  0.0408966   0.07105588]\n",
      "[-3.14643807e-05  1.65977523e-01  4.23177176e-02 -2.08448659e-01]\n",
      "[ 0.00328809  0.36046962  0.03814874 -0.48748793]\n",
      "[ 0.01049748  0.16483076  0.02839899 -0.18303014]\n",
      "[ 0.01379409 -0.03068579  0.02473838  0.11847461]\n",
      "[ 0.01318038 -0.22615329  0.02710788  0.4188585 ]\n",
      "[ 0.00865731 -0.42164867  0.03548505  0.71996257]\n",
      "[ 2.24338562e-04 -2.27035184e-01  4.98842965e-02  4.38656520e-01]\n",
      "[-0.00431637 -0.42282638  0.05865743  0.74663788]\n",
      "[-0.01277289 -0.6187065   0.07359018  1.05718812]\n",
      "[-0.02514702 -0.81472233  0.09473395  1.37203208]\n",
      "[-0.04144147 -0.62090406  0.12217459  1.11041841]\n",
      "[-0.05385955 -0.81740064  0.14438296  1.43879627]\n",
      "[-0.07020756 -1.01397624  0.17315888  1.77289284]\n",
      "[-0.09048709 -0.82117873  0.20861674  1.53867607]\n",
      "Episode 9 finished after 19 timesteps : Reward 1.0\n",
      "[ 0.04359479  0.01540912  0.04854146 -0.00188862]\n",
      "[ 0.04390297  0.20980252  0.04850369 -0.27886967]\n",
      "[ 0.04809902  0.40420019  0.04292629 -0.55586874]\n",
      "[ 0.05618302  0.598694    0.03180892 -0.83472425]\n",
      "[ 0.0681569   0.79336728  0.01511443 -1.11723621]\n",
      "[ 0.08402425  0.59805027 -0.00723029 -0.81985069]\n",
      "[ 0.09598525  0.40302801 -0.02362731 -0.52945063]\n",
      "[ 0.10404581  0.59847424 -0.03421632 -0.82948394]\n",
      "[ 0.1160153   0.40383633 -0.050806   -0.54775558]\n",
      "[ 0.12409202  0.20946357 -0.06176111 -0.2715032 ]\n",
      "[ 0.1282813   0.0152748  -0.06719117  0.00107837]\n",
      "[ 0.12858679 -0.17882241 -0.0671696   0.27182787]\n",
      "[ 0.12501034 -0.3729248  -0.06173305  0.54259188]\n",
      "[ 0.11755185 -0.56712729 -0.05088121  0.81520273]\n",
      "[ 0.1062093  -0.76151697 -0.03457716  1.09145727]\n",
      "[ 0.09097896 -0.95616659 -0.01274801  1.37309351]\n",
      "[ 0.07185563 -0.7608876   0.01471386  1.07645102]\n",
      "[ 0.05663788 -0.56596309  0.03624288  0.78842163]\n",
      "[ 0.04531862 -0.37135718  0.05201131  0.50735753]\n",
      "[ 0.03789147 -0.17700518  0.06215846  0.2315082 ]\n",
      "[ 0.03435137 -0.37295771  0.06678863  0.54313217]\n",
      "[ 0.02689222 -0.56895158  0.07765127  0.85608877]\n",
      "[ 0.01551318 -0.76504089  0.09477305  1.17214294]\n",
      "[ 2.12365749e-04 -5.71270118e-01  1.18215906e-01  9.10612726e-01]\n",
      "[-0.01121304 -0.76777629  0.13642816  1.23798933]\n",
      "[-0.02656856 -0.9643612   0.16118795  1.5701123 ]\n",
      "[-0.04585579 -1.16099839  0.19259019  1.90842898]\n",
      "Episode 10 finished after 27 timesteps : Reward 1.0\n",
      "[-0.02700728 -0.0278854  -0.04660024  0.0187716 ]\n",
      "[-0.02756499  0.1678728  -0.04622481 -0.28824244]\n",
      "[-0.02420754  0.36362241 -0.05198966 -0.59513847]\n",
      "[-0.01693509  0.55943198 -0.06389243 -0.90373404]\n",
      "[-0.00574645  0.3652309  -0.08196711 -0.6317984 ]\n",
      "[ 0.00155817  0.17134244 -0.09460308 -0.36601351]\n",
      "[ 0.00498502  0.36767252 -0.10192335 -0.68696363]\n",
      "[ 0.01233847  0.5640505  -0.11566262 -1.0099155 ]\n",
      "[ 0.02361948  0.76051018 -0.13586093 -1.3365651 ]\n",
      "[ 0.03882968  0.95705681 -0.16259223 -1.66848865]\n",
      "[ 0.05797082  1.15365309 -0.19596201 -2.00708548]\n",
      "Episode 11 finished after 11 timesteps : Reward 1.0\n",
      "[ 0.00549528 -0.02070988 -0.04836448  0.00991585]\n",
      "[ 0.00508108  0.17507112 -0.04816616 -0.29762586]\n",
      "[ 0.0085825   0.37084541 -0.05411868 -0.60510209]\n",
      "[ 0.01599941  0.17652036 -0.06622072 -0.32994441]\n",
      "[ 0.01952982  0.37251942 -0.07281961 -0.64275327]\n",
      "[ 0.0269802   0.56857676 -0.08567467 -0.95744995]\n",
      "[ 0.03835174  0.76473978 -0.10482367 -1.2757728 ]\n",
      "[ 0.05364654  0.96103068 -0.13033913 -1.59935475]\n",
      "[ 0.07286715  1.15743368 -0.16232622 -1.92967168]\n",
      "[ 0.09601582  1.35388039 -0.20091966 -2.26798261]\n",
      "Episode 12 finished after 10 timesteps : Reward 1.0\n",
      "[ 0.02796558 -0.04132376  0.04666499  0.01310009]\n",
      "[ 0.02713911 -0.23708281  0.04692699  0.32013353]\n",
      "[ 0.02239745 -0.04265948  0.05332966  0.04261107]\n",
      "[ 0.02154426 -0.238504    0.05418188  0.35163169]\n",
      "[ 0.01677418 -0.43435292  0.06121451  0.66089564]\n",
      "[ 0.00808712 -0.2401338   0.07443243  0.38809845]\n",
      "[ 0.00328445 -0.43622901  0.0821944   0.70328977]\n",
      "[-0.00544013 -0.63238807  0.09626019  1.02067296]\n",
      "[-0.01808789 -0.43867137  0.11667365  0.75969992]\n",
      "[-0.02686132 -0.63519105  0.13186765  1.08669961]\n",
      "[-0.03956514 -0.44203129  0.15360164  0.8381323 ]\n",
      "[-0.04840577 -0.63887961  0.17036429  1.17490989]\n",
      "[-0.06118336 -0.83575542  0.19386249  1.51579354]\n",
      "Episode 13 finished after 13 timesteps : Reward 1.0\n",
      "[-0.012605   -0.04771194  0.02755106 -0.02939534]\n",
      "[-0.01355924  0.1470043   0.02696315 -0.31325987]\n",
      "[-0.01061916  0.34173197  0.02069796 -0.597319  ]\n",
      "[-0.00378452  0.53655827  0.00875158 -0.88341109]\n",
      "[ 0.00694665  0.73156028 -0.00891664 -1.17332998]\n",
      "[ 0.02157785  0.92679699 -0.03238324 -1.46879486]\n",
      "[ 0.04011379  1.1222999  -0.06175914 -1.77141448]\n",
      "[ 0.06255979  1.31806181 -0.09718743 -2.08264316]\n",
      "[ 0.08892103  1.51402319 -0.13884029 -2.40372627]\n",
      "[ 0.11920149  1.71005596 -0.18691482 -2.73563388]\n",
      "Episode 14 finished after 10 timesteps : Reward 1.0\n",
      "[-0.01991589 -0.00130528 -0.03808778 -0.04881071]\n",
      "[-0.01994199  0.19434153 -0.03906399 -0.35326319]\n",
      "[-0.01605516 -0.0002038  -0.04612925 -0.07314971]\n",
      "[-0.01605924 -0.19463512 -0.04759225  0.20462983]\n",
      "[-0.01995194  0.00113398 -0.04349965 -0.10267816]\n",
      "[-0.01992926 -0.19333845 -0.04555321  0.17596968]\n",
      "[-0.02379603 -0.38777987 -0.04203382  0.45394124]\n",
      "[-0.03155163 -0.58228302 -0.032955    0.73308396]\n",
      "[-0.04319729 -0.77693451 -0.01829332  1.01521564]\n",
      "[-0.05873598 -0.58157344  0.002011    0.71684513]\n",
      "[-0.07036745 -0.77672316  0.0163479   1.01016036]\n",
      "[-0.08590191 -0.58182316  0.03655111  0.72265549]\n",
      "[-0.09753837 -0.38722534  0.05100422  0.44169734]\n",
      "[-0.10528288 -0.19286085  0.05983816  0.1655185 ]\n",
      "[-0.1091401   0.00135575  0.06314853 -0.10770309]\n",
      "[-0.10911298 -0.19461162  0.06099447  0.20421539]\n",
      "[-0.11300521 -0.00041256  0.06507878 -0.06862023]\n",
      "[-0.11301347 -0.19640426  0.06370637  0.24386463]\n",
      "[-0.11694155 -0.00224737  0.06858367 -0.02806291]\n",
      "[-0.1169865   0.19182744  0.06802241 -0.29834293]\n",
      "[-0.11314995  0.38591715  0.06205555 -0.56882104]\n",
      "[-0.10543161  0.58011634  0.05067913 -0.84132651]\n",
      "[-0.09382928  0.7745112   0.0338526  -1.11765114]\n",
      "[-0.07833906  0.57896177  0.01149958 -0.81454427]\n",
      "[-0.06675982  0.38368424 -0.00479131 -0.51826655]\n",
      "[-0.05908614  0.57887332 -0.01515664 -0.81245546]\n",
      "[-0.04750867  0.77419957 -0.03140575 -1.10986705]\n",
      "[-0.03202468  0.96971978 -0.05360309 -1.41223453]\n",
      "[-0.01263028  0.77530169 -0.08184778 -1.13677802]\n",
      "[ 0.00287575  0.58134011 -0.10458334 -0.87084601]\n",
      "[ 0.01450255  0.38778423 -0.12200026 -0.61279002]\n",
      "[ 0.02225824  0.19455944 -0.13425606 -0.3608863 ]\n",
      "[ 0.02614943  0.00157586 -0.14147379 -0.11336867]\n",
      "[ 0.02618094 -0.19126535 -0.14374116  0.13154851]\n",
      "[ 0.02235564  0.0055918  -0.14111019 -0.20280645]\n",
      "[ 0.02246747  0.2024202  -0.14516632 -0.53646333]\n",
      "[ 0.02651588  0.00960563 -0.15589559 -0.29281271]\n",
      "[ 0.02670799 -0.18298986 -0.16175184 -0.0530708 ]\n",
      "[ 0.02304819  0.01403724 -0.16281326 -0.39210161]\n",
      "[ 0.02332894 -0.17844503 -0.17065529 -0.15485241]\n",
      "[ 0.01976004  0.01865719 -0.17375234 -0.49614048]\n",
      "[ 0.02013318 -0.17364373 -0.18367515 -0.26285885]\n",
      "[ 0.01666031 -0.3657338  -0.18893232 -0.03326782]\n",
      "[ 0.00934563 -0.16847561 -0.18959768 -0.37910611]\n",
      "[ 0.00597612  0.02876172 -0.1971798  -0.72506877]\n",
      "Episode 15 finished after 45 timesteps : Reward 1.0\n",
      "[-0.00779454 -0.02736859 -0.02790412  0.02047211]\n",
      "[-0.00834192  0.16814219 -0.02749468 -0.28088265]\n",
      "[-0.00497907 -0.02657699 -0.03311233  0.00300332]\n",
      "[-0.00551061 -0.2212088  -0.03305227  0.28505775]\n",
      "[-0.00993479 -0.41584415 -0.02735111  0.56713571]\n",
      "[-0.01825167 -0.22034942 -0.0160084   0.26596307]\n",
      "[-0.02265866 -0.41523927 -0.01068914  0.55355413]\n",
      "[-3.09634443e-02 -6.10209505e-01  3.81945783e-04  8.42850224e-01]\n",
      "[-0.04316763 -0.41509277  0.01723895  0.55028743]\n",
      "[-0.05146949 -0.61045256  0.0282447   0.84835158]\n",
      "[-0.06367854 -0.80594813  0.04521173  1.14978081]\n",
      "[-0.0797975  -0.61144448  0.06820735  0.87161119]\n",
      "[-0.09202639 -0.41731316  0.08563957  0.60112872]\n",
      "[-0.10037266 -0.61352212  0.09766215  0.91951082]\n",
      "[-0.1126431  -0.80981881  0.11605236  1.24121983]\n",
      "[-0.12883947 -1.00622349  0.14087676  1.56788803]\n",
      "[-0.14896394 -1.20271898  0.17223452  1.90099223]\n",
      "Episode 16 finished after 17 timesteps : Reward 1.0\n",
      "[-0.01948951 -0.02669683  0.00917438  0.04970103]\n",
      "[-0.02002345 -0.22194912  0.0101684   0.34526438]\n",
      "[-0.02446243 -0.41721423  0.01707368  0.64113636]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.03280672 -0.22233441  0.02989641  0.35387864]\n",
      "[-0.03725341 -0.02765003  0.03697398  0.07077082]\n",
      "[-0.03780641  0.16692286  0.0383894  -0.21002119]\n",
      "[-0.03446795  0.36147548  0.03418898 -0.49035138]\n",
      "[-0.02723844  0.16588833  0.02438195 -0.1870925 ]\n",
      "[-0.02392067  0.36065311  0.0206401  -0.47198526]\n",
      "[-0.01670761  0.55547755  0.01120039 -0.75809191]\n",
      "[-0.00559806  0.75044337 -0.00396144 -1.04722946]\n",
      "[ 0.00941081  0.55537422 -0.02490603 -0.75579269]\n",
      "[ 0.02051829  0.75083046 -0.04002189 -1.05620774]\n",
      "[ 0.0355349   0.55626112 -0.06114604 -0.77635072]\n",
      "[ 0.04666012  0.36203104 -0.07667306 -0.50351582]\n",
      "[ 0.05390074  0.16806872 -0.08674337 -0.23594691]\n",
      "[ 0.05726212 -0.02571372 -0.09146231  0.02816328]\n",
      "[ 0.05674784 -0.21941311 -0.09089905  0.29064549]\n",
      "[ 0.05235958 -0.02312053 -0.08508614 -0.02926532]\n",
      "[ 0.05189717 -0.21692576 -0.08567144  0.23540569]\n",
      "[ 0.04755866 -0.02069091 -0.08096333 -0.08302363]\n",
      "[ 0.04714484 -0.21456456 -0.0826238   0.18305699]\n",
      "[ 0.04285355 -0.01836353 -0.07896266 -0.13450434]\n",
      "[ 0.04248628  0.17779547 -0.08165275 -0.45101691]\n",
      "[ 0.04604218 -0.01608248 -0.09067309 -0.18514816]\n",
      "[ 0.04572054 -0.20979797 -0.09437605  0.07761004]\n",
      "[ 0.04152458 -0.40344918 -0.09282385  0.3390888 ]\n",
      "[ 0.03345559 -0.20713744 -0.08604207  0.01863785]\n",
      "[ 0.02931284 -0.40092681 -0.08566932  0.28298141]\n",
      "[ 0.02129431 -0.20469405 -0.08000969 -0.03544423]\n",
      "[ 0.01720043 -0.39858291 -0.08071857  0.2309609 ]\n",
      "[ 0.00922877 -0.59246422 -0.07609935  0.49713047]\n",
      "[-0.00262052 -0.7864353  -0.06615674  0.76489339]\n",
      "[-0.01834922 -0.98058689 -0.05085888  1.03604779]\n",
      "[-0.03796096 -1.17499718 -0.03013792  1.31234009]\n",
      "[-0.0614609  -0.97950688 -0.00389112  1.01037861]\n",
      "[-0.08105104 -1.17457669  0.01631645  1.30183711]\n",
      "[-0.10454258 -1.36990182  0.04235319  1.59958263]\n",
      "[-0.13194061 -1.5654991   0.07434485  1.90516357]\n",
      "[-0.16325059 -1.37125483  0.11244812  1.63643926]\n",
      "[-0.19067569 -1.17761723  0.1451769   1.38080739]\n",
      "[-0.21422804 -0.98457471  0.17279305  1.13682197]\n",
      "[-0.23391953 -1.18148304  0.19552949  1.47833477]\n",
      "Episode 17 finished after 43 timesteps : Reward 1.0\n",
      "[-0.04658839  0.03604439  0.01109036  0.00380185]\n",
      "[-0.0458675   0.23100555  0.01116639 -0.2853614 ]\n",
      "[-0.04124739  0.42596648  0.00545917 -0.57450172]\n",
      "[-0.03272806  0.23076842 -0.00603087 -0.280104  ]\n",
      "[-0.02811269  0.03573301 -0.01163295  0.01067072]\n",
      "[-0.02739803 -0.15922019 -0.01141953  0.29966073]\n",
      "[-0.03058244  0.03606266 -0.00542632  0.00339829]\n",
      "[-0.02986118  0.23126201 -0.00535835 -0.29099176]\n",
      "[-2.52359422e-02  3.62168687e-02 -1.11781895e-02 -3.59877484e-06]\n",
      "[-0.0245116  -0.158743   -0.01117826  0.28913162]\n",
      "[-0.02768646  0.03653655 -0.00539563 -0.00705575]\n",
      "[-0.02695573  0.23173547 -0.00553674 -0.30143617]\n",
      "[-0.02232102  0.42693589 -0.01156547 -0.59586012]\n",
      "[-0.01378231  0.62221778 -0.02348267 -0.89216352]\n",
      "[-0.00133795  0.4274221  -0.04132594 -0.60695384]\n",
      "[ 0.00721049  0.62309677 -0.05346502 -0.91236161]\n",
      "[ 0.01967243  0.81889971 -0.07171225 -1.22135757]\n",
      "[ 0.03605042  0.62477134 -0.0961394  -0.95197879]\n",
      "[ 0.04854585  0.82104639 -0.11517898 -1.27325327]\n",
      "[ 0.06496678  0.62756692 -0.14064404 -1.01874478]\n",
      "[ 0.07751811  0.43457108 -0.16101894 -0.77332267]\n",
      "[ 0.08620954  0.24198733 -0.17648539 -0.53531909]\n",
      "[ 0.09104928  0.43909445 -0.18719177 -0.87800499]\n",
      "[ 0.09983117  0.63619927 -0.20475187 -1.22321084]\n",
      "Episode 18 finished after 24 timesteps : Reward 1.0\n",
      "[0.04390796 0.01641308 0.02388299 0.02983016]\n",
      "[ 0.04423622  0.21118454  0.02447959 -0.25522278]\n",
      "[0.04845991 0.01572178 0.01937513 0.0450798 ]\n",
      "[ 0.04877435  0.21056062  0.02027673 -0.24142767]\n",
      "[0.05298556 0.01515498 0.01544818 0.05758148]\n",
      "[ 0.05328866 -0.18018502  0.01659981  0.35509811]\n",
      "[ 0.04968496 -0.37553902  0.02370177  0.65296885]\n",
      "[ 0.04217418 -0.180755    0.03676115  0.36784256]\n",
      "[ 0.03855908 -0.3763795   0.044118    0.6718864 ]\n",
      "[ 0.03103149 -0.1818977   0.05755572  0.39341404]\n",
      "[0.02739353 0.01236229 0.06542401 0.1194186 ]\n",
      "[ 0.02764078  0.20648884  0.06781238 -0.15192731]\n",
      "[0.03177056 0.01046472 0.06477383 0.16135462]\n",
      "[ 0.03197985 -0.18552186  0.06800092  0.47374818]\n",
      "[ 0.02826941 -0.38153494  0.07747589  0.78706514]\n",
      "[ 0.02063871 -0.57763084  0.09321719  1.10308176]\n",
      "[ 0.0090861  -0.38385038  0.11527883  0.84103922]\n",
      "[ 0.00140909 -0.19047492  0.13209961  0.5867182 ]\n",
      "[-0.00240041  0.00257367  0.14383397  0.33839265]\n",
      "[-0.00234894 -0.1942708   0.15060183  0.67275187]\n",
      "[-0.00623435 -0.0015274   0.16405686  0.43101903]\n",
      "[-0.0062649  -0.19854604  0.17267724  0.77059554]\n",
      "[-0.01023582 -0.39557036  0.18808916  1.11225208]\n",
      "Episode 19 finished after 23 timesteps : Reward 1.0\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "env = gym.make('CartPole-v0')\n",
    "for i_episode in range(20):\n",
    "    observation = env.reset()\n",
    "    for t in range(100):\n",
    "        env.render()\n",
    "        print(observation)\n",
    "        action = env.action_space.sample()\n",
    "        observation, reward, done, info = env.step(action)\n",
    "        if done:\n",
    "            print(\"Episode {} finished after {} timesteps : Reward {}\".format(i_episode, t+1, reward))\n",
    "            break\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spaces\n",
    "> + In the examples above, we’ve been sampling random actions from the environment’s action space. But what actually are those actions? \n",
    "+ Every environment comes with an `action_space` and an `observation_space`. \n",
    "+ These attributes are of type `Space`, and they describe the format of valid actions and observations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discrete(2)\n",
      "Box(4,)\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "env = gym.make('CartPole-v0')\n",
    "print(env.action_space)         #> Discrete(2)\n",
    "print(env.observation_space)    #> Box(4,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> + The `Discrete` space allows a fixed range of non-negative numbers, so in this case valid `actions` are either 0 or 1. \n",
    "+ The `Box` space represents an n-dimensional box, so valid `observations` will be an array of 4 numbers. We can also check the `Box`’s bounds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.8000002e+00 3.4028235e+38 4.1887903e-01 3.4028235e+38]\n",
      "[-4.8000002e+00 -3.4028235e+38 -4.1887903e-01 -3.4028235e+38]\n"
     ]
    }
   ],
   "source": [
    "print(env.observation_space.high)\n",
    "#> array([ 2.4       ,         inf,  0.20943951,         inf])\n",
    "print(env.observation_space.low)\n",
    "#> array([-2.4       ,        -inf, -0.20943951,        -inf])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> + This introspection can be helpful to write generic code that works for many different environments. `Box` and `Discrete` are the most common `Spaces`. You can sample from a `Space` or check that something belongs to it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gym import spaces\n",
    "space = spaces.Discrete(8) # Set with 8 elements {0, 1, 2, ..., 7}\n",
    "x = space.sample()\n",
    "assert space.contains(x)\n",
    "assert space.n == 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> + For `CartPole-v0`, one of the actions applies force to the left, and one of them applies force to the right."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [NOTE]: \n",
    "+ **Check out the cartpole experiment on a visualization window.**\n",
    "+ **The experiment fails when the pendulum tilts reaching an angle of 15 degrees or the moving range larger than 2.4 units !!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
